{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romiebanerjee/laplace/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e7ae8c",
      "metadata": {
        "id": "f0e7ae8c"
      },
      "source": [
        "# Laplace-BNN inference with KFAC posterior and GLM predictive\n",
        "\n",
        "**Author**: Romie Banerjee\n",
        "<!-- **Last Updated**: `YYYY-MM-DD`   -->\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Overview\n",
        "A tutorial on Laplace-BNN inference. Focus on calculating the *GLM predictive*. The posterior is calculated using KFAC.\n",
        "\n",
        "## 2. BNN\n",
        "A **Bayesian neural network (BNN)** is an infinite family of neural networks, parametrized as a map $f:X \\times \\Theta \\to Y$, where the spaces  $X$, $\\Theta$ and $Y$ are respectively the imput, model and output spaces. The mapping is coordinatized as $R^n \\times R^w \\to R^d$. The mapping $(x, \\theta) \\mapsto f(x, \\theta)$ expresses the evaluation of the model $\\theta$ at the input $x$. The family of models is equipped with a probability measure, the posterior. The final inference step estimates the predictive distribution in the output space.\n",
        "\n",
        "### BNN Inference\n",
        "- Given the model $\\Theta$ (space of NN weights) and prior distribution $P(\\Theta)$\n",
        "- training data $D$\n",
        "- The posterior distribution $P(\\Theta |D)$, estimated by approximations (monte carlo, variational infernce etc.).\n",
        "- The BNN predictive is the output distribution on $Y$, defined as the push-forward prob measure on $\\Theta$, via the map $f(x, -): \\Theta \\to Y$.\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "  A[model + prior] --> B[Data];\n",
        "  B --> C[BNN Posterior];\n",
        "  C --> D[BNN Predictive];\n",
        "```\n",
        "\n",
        "\n",
        "## 3. Laplace-BNN\n",
        "A **Laplace-BNN** is BNN where the posterior is replaced by a *Gaussian around the MAP* using Laplace approximation applied to the true model posterior. The MAP is a model point-estimate obtained through ERM.\n",
        "\n",
        "### Laplace-BNN Inference\n",
        "- $ P(\\Theta|D) \\sim N(\\theta_{MAP}, \\Sigma) $\n",
        "- The covariance $\\Sigma$ is inverse of the Loss Hessian, $\\left( \\frac{\\partial^2}{\\partial \\theta^2} Loss(\\theta)|_{\\theta_{MAP}} \\right)^{-1}$\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "  A[\"model (point-estimate)\"] --> C[Gaussian posterior:];\n",
        "  C --> D[Laplace-BNN Predictive];\n",
        "```\n",
        "\n",
        "### Laplace-BNN Inference with KFAC posterior\n",
        "\n",
        "- The Hessian matrix is replaced by the Generalized-Gauss-Newton approximation, i.e. the Fisher information matrix $I_{\\theta}(\\theta_{MAP}) := COV \\left( \\nabla_{\\theta}Loss |_{\\theta_{MAP}} \\right)$\n",
        "- $P(\\Theta|D) \\sim N(\\theta_{MAP}, I_{\\theta}(\\theta_{MAP})^{-1})$\n",
        "- The Fisher is further approximated by the **KFAC** matrix, a *block-diagonal* form (block per layer), where each block is in a *kronecker-factored*  form $I_{\\theta}(\\theta_{MAP})_{KFAC} =\n",
        "  \\begin{pmatrix}\n",
        "  Q_{(1)}\\otimes H_{(1)}&  &\\\\\n",
        "  & \\ddots & \\\\\n",
        "  && Q_{(L)} \\otimes H_{(L)}\n",
        "  \\end{pmatrix}$\n",
        "- The l-th block $Q_l\\otimes H_l$ is the Fisher for the l-th layer.\n",
        "- The KFAC posterior covariance $\\Sigma_{KFAC} =\n",
        "  \\begin{pmatrix}\n",
        "  Q_{(1)}^{-1}\\otimes H_{(1)}^{-1}&  &\\\\\n",
        "  & \\ddots & \\\\\n",
        "  && Q_{(L)}^{-1} \\otimes H_{(L)}^{-1}\n",
        "  \\end{pmatrix}$\n",
        "- Other variant of approximate Fisher include eKFAC and INF [3]\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "  A[\"model (point-estimate)\"] --> C[KFAC posterior];\n",
        "  C --> D[Laplace-BNN Predictive];\n",
        "```\n",
        "\n",
        "## 4. Laplace-BNN predictive estimators\n",
        "\n",
        "\n",
        "### Laplace-BNN predictive: GLM\n",
        "The **Generalized Linear Model (GLM)** is the linearization of the BNN $f: X \\times \\Theta \\to Y$ at $\\theta = \\theta_{MAP}$.\n",
        "- $f_{lin}(x, \\theta) = f(x, \\theta_{MAP}) + J(x)(\\theta - \\theta_{MAP})$\n",
        "- where $J(x)$ is the jacobian $\\frac{\\partial}{\\partial\\theta} f(x, \\theta)|_{\\theta = \\theta_{MAP}}$.\n",
        "- The GLM predictive is a Gaussian: $N(f_{MAP}(x), J(x)@\\Sigma @J(x)^T)$\n",
        "- where $\\Sigma$ is the Laplace posterior Gaussian (using GGN approximation $\\Sigma = I_{\\theta}(\\theta_{MAP})^{-1}$)\n",
        "- *NOTE*: Since the GLM predictive is a gaussian with mean $f_{MAP}(x)$, it can be read as the prediction uncertainty of the origina model $f_{MAP}$.\n",
        "- *NOTE*: In order to use GLM directy (i.e. using the closed form of the GLM covariance) one has to compute $J(x)$ for every $x$, this can be compute heavy when the output space is high-dimensional.\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "  A[\"Gaussian posterior\"] --> C[jacobian];\n",
        "  C --> D[GLM Predictive];\n",
        "```\n",
        "### Laplace-BNN predictive: MC-GLM\n",
        "Empirically estimate the GLM predictive: apply MCI to the GLM model\n",
        "- Input $x$\n",
        "- Sample weights $\\theta_1, \\ldots, \\theta_k \\sim N\\left( \\theta_{MAP}, I_{\\theta}(\\theta_{MAP})^{-1}\\right)$\n",
        "- Multiple Feed forwards $f_{lin}(x, \\theta_1), \\ldots, f_{lin}(x, \\theta_k)$\n",
        "- Compute the GLM predictive $P(y|x)$ statistics: empirical mean and covariance\n",
        "- The empirical mean, $\\bar{f}_{lin}(x) = MEAN\\left[ f_{lin}(x, \\theta_i)\\right] = f_{lin}(x, MEAN(\\theta_i)) = f_{MAP}(x) + J(x)(MEAN(\\theta_i) - \\theta_{MAP})$, converges to $f_{MAP}(x)$\n",
        "- The empirical covariance $\\frac{1}{k-1}\\sum_{i=1}^k \\left( f_{lin}(x, \\theta_i) - \\bar{f}_{lin}(x) \\right) @ \\left( f_{lin}(x, \\theta_i) - \\bar{f}_{lin}(x) \\right)^T$, converges to $J(x)@\\Sigma @J(x)^T$\n",
        "- Simplify the empirical covarinace further by $\\frac{1}{k-1}\\sum_{i=1}^k \\left( J(x)@(\\theta_i - \\theta_{MAP}) \\right) @ \\left( J(X)@(\\theta_i - \\theta_{MAP} \\right)^T$\n",
        "- Numerical differentiation: $J(x)@(\\theta_i - \\theta_{MAP}) \\sim \\frac{f(x, \\theta_{MAP} + h*\\eta_i) - f(x, \\theta_{MAP})}{h}$, where $h$ is a small scalar, $\\eta_i = \\theta_i - \\theta_{MAP}$\n",
        "```mermaid\n",
        "graph LR\n",
        "    B[Gaussian Posterior];\n",
        "    D@{ shape: procs, label: \"sample models from GLM\"};\n",
        "    B --> D;\n",
        "    D --> A[MC-GLM predictive];\n",
        "```\n",
        "\n",
        "### Laplace-BNN predictive: LR-GLM\n",
        "A **low-rank approximation** of the GLM predictive covariance $\\Sigma(x) = J(x)@\\Sigma @J(x)^T$ utilizing the sparsity of the eigenspectrum of the Fisher information matrix.\n",
        "\n",
        "- Input $x$\n",
        "- Choose $K$ Eigen-vectors (scaled by their eigenvalues) from the TopK  $ v_1, \\ldots, v_m, (K << w)$ from the high-end of the eigenspectrum of $I_{\\theta}(\\theta_{MAP})$\n",
        "- Multiple Feed forwards $f(x, v_1), \\ldots, f(x, v_m)$\n",
        "- $A(x) :=\n",
        "\\begin{pmatrix}\n",
        "| & & | \\\\\n",
        "D_{v_1}f & \\cdots & D_{v_n}f \\\\\n",
        "| &  & |\n",
        "\\end{pmatrix}\n",
        "\\in \\mathbb{R}^{d \\times K}$, where $D_{v}f = \\frac{f(x, \\theta_{MAP} + h*v) - f(x, \\theta_{MAP})}{h}$, $h$ is a small scalar\n",
        "- $\\Sigma(x)_{LR} = A(x)@A(x)^T$\n",
        "```mermaid\n",
        "graph LR\n",
        "    B[model Fisher]\n",
        "    D@{ shape: procs, label: \"Eigenvectors from inverse fisher \"}\n",
        "    B --> D\n",
        "    D --> A[LR-GLM predictive]\n",
        "```\n",
        "## 4. Additional Details\n",
        "\n",
        "### Sampling from the Gaussian with KFAC covariance\n",
        "- A sample from a gaussian $z \\sim N(\\mu, \\Sigma)$ can be obtained by first sampling $x \\sim N(0, I_n)$ from an identity-covariance zero-mean Gaussian, and appling the affine transformation $z= \\mu  + Chol(\\Sigma)@ x$.\n",
        "- For a KFAC Laplace-BNN the covariance of the form\n",
        "  $\\begin{pmatrix}\n",
        "  Q_{(1)}^{-1}\\otimes H_{(1)}^{-1}&  &\\\\\n",
        "  & \\ddots & \\\\\n",
        "  && Q_{(L)}^{-1} \\otimes H_{(L)}^{-1}\n",
        "  \\end{pmatrix}$\n",
        "- The Choleksy decomposes block-wise and commutes with inverses and kronecker products:\n",
        "  $Chol\\begin{pmatrix}\n",
        "  Q_{(1)}^{-1}\\otimes H_{(1)}^{-1}&  &\\\\\n",
        "  & \\ddots & \\\\\n",
        "  && Q_{(L)}^{-1} \\otimes H_{(L)}^{-1}\n",
        "  \\end{pmatrix}$ =\n",
        "$\\begin{pmatrix}\n",
        "Chol(Q_{(1)})^{-1}\\otimes Chol(H_{(1)})^{-1}& &\\\\\n",
        "& \\ddots & \\\\\n",
        "&& Chol(Q_{(L)})^{-1}\\otimes Chol(H_{(L)})^{-1}& &\\\\\n",
        "\\end{pmatrix}$\n",
        "- The samples care obtained layer-wise: $z_l = \\left( Ch(Q_{(1)})^{-1}\\otimes Ch(H_{(1)})^{-1} \\right)@ x_l$ where $x \\sim N(0, I_l)$\n",
        "\n",
        "### Computing the closed form GLM predictive\n",
        "In order to compute the GLM closed for, one needs to compute\n",
        "- The KFAC covariance matrix (independent of the input $x$)\n",
        "- The Jacobian $J(x)$\n",
        "- matrix product $J(x) @ \\Sigma @ J(x)^T$\n",
        "\n",
        "Given the block-wise kronecker-factored form of the KFAC $\\Sigma$, the jacobian must be expressed in a compatible format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7947c83f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7947c83f",
        "outputId": "52b02fa6-8bc0-4135-f2bb-2abfc13ce1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "import  os\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/romiebanerjee/laplace.git\n",
        "%cd laplace\n",
        "from kfac.kfac import KFAC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hYDA7fhvA1h",
        "outputId": "97fa4468-1ad9-4397-d9c5-a3c3530a5a1b"
      },
      "id": "0hYDA7fhvA1h",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'laplace'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 24 (delta 2), reused 24 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (24/24), 281.62 KiB | 56.32 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/laplace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b9b38d3",
      "metadata": {
        "id": "0b9b38d3"
      },
      "outputs": [],
      "source": [
        "#training scripts\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "\n",
        "def train_fisher(kfac:KFAC,\n",
        "                fisher_loader: DataLoader,\n",
        "                criterion: torch.nn.modules.loss,\n",
        "                ):\n",
        "    '''Empirical fisher computation by KFAC\n",
        "        Update kfac state dict\n",
        "    '''\n",
        "    for module in kfac.model.modules():\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            module.eval()  # Use running mean/var instead of batch stats\n",
        "        else:\n",
        "            module.train()\n",
        "\n",
        "    progress_bar = tqdm(fisher_loader, desc=f\"Epoch {epoch}\")\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = kfac.model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward() #NO OPTIMATION, ONLY CALCULATE GRADIENT\n",
        "        kfac.update_fisher(log = False)\n",
        "        progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d0d5e12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d0d5e12",
        "outputId": "02d1e7d7-544f-4acc-de0a-02f2dc339e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.79MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.92MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to tensor (range [0, 1])\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std of MNIST\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "#custom transforms\n",
        "class AddSaltPepperNoise(object):\n",
        "    def __init__(self, prob=0.05):\n",
        "        self.prob = prob  # Probability of noise\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        noisy_tensor = tensor.clone()\n",
        "        mask = torch.rand(tensor.size()) < self.prob\n",
        "        noisy_tensor[mask] = torch.randint(0, 2, mask.shape).float()[mask]\n",
        "        return noisy_tensor\n",
        "# Define transforms with noise\n",
        "\n",
        "saltpepper_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    AddSaltPepperNoise(prob=0.1)  # 10% pixels corrupted\n",
        "])\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=saltpepper_transform\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0b008e4e",
      "metadata": {
        "id": "0b008e4e"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "model = resnet18(num_classes=10)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Adjust for 1-channel input\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model `model`"
      ],
      "metadata": {
        "id": "0qv4IlWDy0j7"
      },
      "id": "0qv4IlWDy0j7"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b190bd1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b190bd1f",
        "outputId": "693290cf-4888-4480-d9e2-2c5a6d704632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 938/938 [00:27<00:00, 34.43it/s, Loss=0.0092]\n",
            "Epoch 1: 100%|██████████| 938/938 [00:25<00:00, 36.44it/s, Loss=0.0647]\n",
            "Epoch 2: 100%|██████████| 938/938 [00:25<00:00, 36.44it/s, Loss=0.0033]\n",
            "Epoch 3: 100%|██████████| 938/938 [00:25<00:00, 36.41it/s, Loss=0.0102]\n",
            "Epoch 4: 100%|██████████| 938/938 [00:25<00:00, 36.43it/s, Loss=0.0098]\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train for 5 epochs\n",
        "for epoch in range(5):\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initailize `KFAC` object `mykfac` with input `model`. This the bayesian object around the *trained* model `model`.\n",
        "\n",
        "The BNN `mykfac` has features\n",
        "- `mykac.model` storing the central pre-trained model\n",
        "- `mykfac.fisher` storing posterior information (from Laplace approximation)\n",
        "\n",
        "During the training run `fisher_train` the gradients of the loss function w.r.t the model weights at the trained model prams $\\frac{\\partial L}{\\partial \\theta }|_{\\theta = \\theta*}$ are calculated, stored and empirical covariance calculated. This is done by adding the outer product of the gradient vectors one-at-at-time (hence batch_size = 1) $\\sum_i \\nabla_i * \\nabla_i^T$ going through the training set. NOTE: No optimization is performed, as that would move us away from the trained model. The outer product is not calulated directly, but done layer-wise and using kronecker-factorization. The end result is an attribute `mykfac.fisher` which is `dict` object storing the layer-wise kronecker-factored emiprical fisher matrices.\n",
        "\n",
        "- `mykfac.fisher[layer_name] = (Q,H)`\n",
        "\n",
        "Q and H square matrices such that $Q\\otimes H$ approximate the empirical fisher in layer `layer_name`.\n"
      ],
      "metadata": {
        "id": "WkPm173hy-H5"
      },
      "id": "WkPm173hy-H5"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "33bbe49d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33bbe49d",
        "outputId": "86c89bd8-45c8-4cc6-dc07-0c85eac9ed0c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4:   0%|          | 0/60000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
            "Epoch 4: 100%|██████████| 60000/60000 [23:21<00:00, 42.81it/s, Loss=0.0008]\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "fisher_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "mykfac = KFAC(model, device = device)\n",
        "\n",
        "train_fisher(mykfac, fisher_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the fisher is saved, we have to invert it. Along the way we also compute the eigenvalues, and cholesky decompotion. Everything is done layer-wise and utilizing the (Q,H) factorization.\n",
        "\n",
        "We end up with the following `dict` features of our bayesian NN `mykfac`\n",
        "\n",
        "`mykfac.eigvals(), mykfac.eigvecs(), mykfac.invchol(), mykfac.invfisher()`\n",
        "\n",
        "`mykfac.eigvals[layer_name]` = [eigenvalues of Q, eigenvalues of H]\n",
        "\n",
        "`mykfac.eigvals[layer_name]` = [eigenvectors of Q, eigenvectors of H]\n",
        "\n",
        "`mykfac.invchol[layer_name]` = $[\\text{chol}(Q)^{-1}, \\text{chol}(H)^{-1}]$\n",
        "\n",
        "`mykfac.invfisher[layer_name]` = $[Q^{-1}, H^{-1}]$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kY4ov-ZR3UEp"
      },
      "id": "kY4ov-ZR3UEp"
    },
    {
      "cell_type": "code",
      "source": [
        "mykfac.kf_eigens()\n",
        "mykfac.invert_cholesky()\n",
        "mykfac.invert_fisher()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v94zInlj-lp_",
        "outputId": "1a1a21e2-c28e-4b3e-b219-b74bcd6f323c"
      },
      "id": "v94zInlj-lp_",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating eigenvalues of the fisher\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing inverted Cholesky of fisher ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15it [00:02,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Error in layer layer3.1.conv2 index :[14/21]\n",
            "linalg.cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 1046 is not positive-definite).\n",
            "\n",
            "\n",
            "Error in layer layer4.0.conv1 index :[15/21]\n",
            "linalg.cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 369 is not positive-definite).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [00:10,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Error in layer layer4.0.downsample.0 index :[17/21]\n",
            "linalg.cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 138 is not positive-definite).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:27,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Error in layer fc index :[20/21]\n",
            "linalg.cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 10 is not positive-definite).\n",
            "Computing inverse fisher ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:00, 11117.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Error in layer layer3.1.conv2 index :[14/21]\n",
            "'NoneType' object has no attribute 't'\n",
            "\n",
            "\n",
            "Error in layer layer4.0.conv1 index :[15/21]\n",
            "'NoneType' object has no attribute 't'\n",
            "\n",
            "\n",
            "Error in layer layer4.0.downsample.0 index :[17/21]\n",
            "'NoneType' object has no attribute 't'\n",
            "\n",
            "\n",
            "Error in layer fc index :[20/21]\n",
            "'NoneType' object has no attribute 't'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "095bb63b",
      "metadata": {
        "id": "095bb63b"
      },
      "outputs": [],
      "source": [
        "for module in mykfac.model.modules():\n",
        "    if isinstance(module, nn.BatchNorm2d):\n",
        "        module.eval()  # Use running mean/var instead of batch stats\n",
        "    else:\n",
        "        module.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "158fefd3",
      "metadata": {
        "id": "158fefd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "a0e274e7-7d4b-4ffc-9ecd-68b6d210f277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicion = tensor([7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x79097b8b1c10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#run base model on example (noisy mnist sample)\n",
        "image, label = next(iter(test_loader))\n",
        "image, label = image.to(device), label.to(device)\n",
        "output = mykfac.model(image)\n",
        "\n",
        "probs = softmax(output, dim=1).cpu().detach().numpy().squeeze()\n",
        "pred = output.argmax(dim=1).cpu()\n",
        "print(f'predicion = {pred}')\n",
        "fig, axes = plt.subplots(2, figsize=(10, 10))\n",
        "axes[0].imshow(image[0].cpu().numpy().squeeze(), cmap = 'gray')\n",
        "axes[1].bar(range(10), probs, color='skyblue')\n",
        "axes[1].set_ylim(0, 1)\n",
        "axes[1].set_title(\"Softmax Probabilities\")\n",
        "axes[1].set_xlabel(\"Digit Class\")\n",
        "axes[1].set_ylabel(\"Probability\")\n",
        "axes[1].axvline(x=pred, color='red', linestyle='--', alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7af38025",
      "metadata": {
        "id": "7af38025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "a57ca2cc-f37e-47b6-f781-88ecfa73cc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 78.37it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'my' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-676446704.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0moutput_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutput_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkf_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my' is not defined"
          ]
        }
      ],
      "source": [
        "#GLM uncertainties\n",
        "\n",
        "import copy\n",
        "\n",
        "n_classes = 10\n",
        "output = mykfac.model(image)\n",
        "\n",
        "gradients = []\n",
        "#compute gradient for every scalar outout (#via one backprop for every dimension in the output logit space)\n",
        "for i in tqdm(range(n_classes)):\n",
        "    out = output[0][i]\n",
        "    mykfac.model.zero_grad()\n",
        "    out.backward(retain_graph=True)\n",
        "    mykfac.update_grad(log = False)\n",
        "    gradients.append(copy.deepcopy(mykfac.grad))\n",
        "\n",
        "\n",
        "output_vars = []\n",
        "for grad in gradients:\n",
        "    output_vars.append(my.kfac.kf_inner(grad, grad))\n",
        "plt.plot(output_vars)\n",
        "plt.xlabel(\"class label\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aefeae34",
      "metadata": {
        "id": "aefeae34"
      },
      "outputs": [],
      "source": [
        "#MC-GLM uncertainties\n",
        "\n",
        "output = mykfac.model(image)\n",
        "eps = 1e-6 #for numerical differentiation\n",
        "mc_preds = []\n",
        "iters = 16 #number of monte-carlo samples\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(iters)):\n",
        "        mykfac.sample_and_replace(eps = eps)\n",
        "        output_logits_mc = mykfac.model(image)\n",
        "        # print(output_logits_mc)\n",
        "        mc_preds.append(output_logits_mc)\n",
        "\n",
        "mc_output_stacked = torch.stack(mc_preds) # shape: (iters, n_classes)\n",
        "\n",
        "A = (mc_output_stacked - output)/eps\n",
        "\n",
        "B = torch.matmul(A.permute(1,2,0), A.permute(1,0,2)) #shape: (n_classes, n_classes)\n",
        "print(torch.diagonal(B))\n",
        "plt.plot(torch.diagonal(B).cpu().detach().numpy().squeeze())\n",
        "plt.xlabel(\"class label\")\n",
        "plt.ylabel('uncertainty')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd09b44d",
      "metadata": {
        "id": "fd09b44d"
      },
      "outputs": [],
      "source": [
        "#We can get the full 10 x 10 covariance matrix\n",
        "plt.imshow(B.detach().cpu().numpy().squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd612f6c",
      "metadata": {
        "id": "fd612f6c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}